% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/batch_processing.R
\name{batch_process_phyloseq}
\alias{batch_process_phyloseq}
\title{Batch Processing for diversityGPT}
\usage{
batch_process_phyloseq(
  phyloseq_list,
  dataset_names = NULL,
  analysis_steps = c("universal", "mechanisms", "hypotheses"),
  output_dir = "diversityGPT_batch_results",
  parallel_cores = NULL,
  cache_results = TRUE,
  generate_reports = FALSE,
  generate_summary = TRUE,
  report_format = "html",
  resume_failed = FALSE,
  save_progress = TRUE,
  study_context = NULL,
  llm_provider = "none"
)
}
\arguments{
\item{phyloseq_list}{List of phyloseq objects to process}

\item{dataset_names}{Optional names for datasets (default: Dataset1, Dataset2, ...)}

\item{analysis_steps}{Vector of analysis steps to perform:
"universal", "mechanisms", "hypotheses", "literature", "validation"}

\item{output_dir}{Directory to save results (default: "diversityGPT_batch_results")}

\item{parallel_cores}{Number of cores for parallel processing (NULL for auto-detect)}

\item{cache_results}{Whether to cache intermediate results}

\item{generate_reports}{Whether to generate individual reports for each dataset}

\item{generate_summary}{Whether to generate a summary report across all datasets}

\item{report_format}{Format for reports: "html", "pdf", or "both"}

\item{resume_failed}{Whether to resume processing of failed datasets}

\item{save_progress}{Whether to save progress after each dataset}

\item{study_context}{Optional study context information for each dataset}

\item{llm_provider}{LLM provider for ecological analysis: "anthropic", "openai", "none"}
}
\value{
A list containing:
\item{results}{List of analysis results for each dataset}
\item{summary_statistics}{Summary statistics across all datasets}
\item{processing_log}{Detailed processing log with timing and errors}
\item{failed_datasets}{List of datasets that failed processing}
\item{batch_metadata}{Metadata about the batch processing run}
}
\description{
Functions for processing multiple datasets efficiently using
parallel processing, caching, and automated workflow management.
Batch Process Multiple Phyloseq Objects
}
\details{
Efficiently processes multiple phyloseq objects through the complete
diversityGPT analysis pipeline with parallel processing and result caching.
}
\examples{
\dontrun{
# Create multiple test datasets
data(GlobalPatterns)
dataset1 <- create_demo_subset(GlobalPatterns, n_samples = 20, seed = 123)
dataset2 <- create_demo_subset(GlobalPatterns, n_samples = 25, seed = 456)
dataset3 <- create_demo_subset(GlobalPatterns, n_samples = 15, seed = 789)

# Batch process with full analysis
batch_results <- batch_process_phyloseq(
  phyloseq_list = list(dataset1, dataset2, dataset3),
  dataset_names = c("Marine", "Soil", "Gut"),
  analysis_steps = c("universal", "mechanisms", "hypotheses"),
  parallel_cores = 2,
  generate_reports = TRUE,
  generate_summary = TRUE
)

print(batch_results)

# Resume failed datasets
resumed_results <- batch_process_phyloseq(
  phyloseq_list = list(dataset1, dataset2, dataset3),
  dataset_names = c("Marine", "Soil", "Gut"),
  output_dir = "diversityGPT_batch_results",
  resume_failed = TRUE
)
}

}
