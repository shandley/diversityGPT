---
title: "Ecological Interpretation and Consensus Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Ecological Interpretation and Consensus Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  warning = FALSE,
  message = FALSE
)
```

## Introduction

One of the most powerful features of diversityGPT is its ability to resolve the "decision confusion" that occurs when different diversity metrics give conflicting results. This vignette demonstrates how to:

1. Use consensus algorithms to synthesize multiple metrics
2. Interpret diversity patterns ecologically
3. Generate testable hypotheses from mathematical patterns
4. Leverage AI for biological insights

```{r setup}
library(diversityGPT)
library(phyloseq)
library(ggplot2)

# Load example data
data(GlobalPatterns)
```

## The Decision Confusion Problem

Traditional diversity analysis often produces conflicting results:

```{r demonstrate-problem}
# Calculate multiple diversity metrics
div_results <- calculate_diversity(
  GlobalPatterns,
  metrics = c("shannon", "simpson", "observed", "chao1", "pielou_evenness")
)

# Show first few samples
head(div_results[, c("shannon", "simpson", "observed")])
```

When Shannon shows significant differences but Simpson doesn't, which do you trust? diversityGPT solves this through consensus analysis and information theory.

## Consensus Analysis Methods

### 1. Simple Weighted Consensus

The most straightforward approach weights metrics by their reliability:

```{r simple-consensus}
# Calculate consensus with bootstrap confidence intervals
consensus_simple <- consensus_diversity(
  div_results,
  method = "weighted",
  n_boot = 100
)

# View consensus values
print(consensus_simple)

# Extract key results
head(consensus_simple$consensus_value)
```

### 2. Information-Theoretic Consensus

This advanced method weights metrics by their information content:

```{r info-consensus}
# Information-weighted consensus
consensus_info <- consensus_diversity(
  div_results,
  method = "information_weighted"
)

# Compare weights assigned to each metric
print(consensus_info$weights)
```

Metrics that capture more unique information receive higher weights.

### 3. Adaptive Consensus

The adaptive method learns optimal weights from your data:

```{r adaptive-consensus}
# Adaptive consensus (best for grouped data)
consensus_adaptive <- consensus_diversity(
  div_results,
  method = "adaptive",
  groups = sample_data(GlobalPatterns)$SampleType
)

# Show how weights adapted to maximize group separation
print(consensus_adaptive$adaptive_weights)
```

## Resolving Metric Conflicts

When metrics disagree, use the conflict resolution framework:

```{r resolve-conflicts}
# Identify conflicting metrics
conflicts <- identify_metric_conflicts(div_results)

# Show samples with high conflict
high_conflict_samples <- conflicts$samples[conflicts$conflict_score > 0.5]
print(paste("Samples with high metric conflict:", 
            paste(high_conflict_samples, collapse = ", ")))

# Resolve conflicts using universal framework
universal_info <- extract_universal_information(GlobalPatterns)

# Use information components to understand conflicts
conflict_resolution <- resolve_metric_conflicts(
  div_results,
  universal_info,
  method = "component_based"
)

print(conflict_resolution$resolution_summary)
```

## Ecological Interpretation Framework

### Understanding Diversity Patterns

diversityGPT interprets mathematical patterns through ecological theory:

```{r ecological-patterns}
# Detect ecological patterns
patterns <- detect_diversity_patterns(
  div_results,
  universal_info,
  sample_metadata = sample_data(GlobalPatterns)
)

# Common patterns and their meanings
pattern_interpretations <- list(
  "High R, Low E" = "Environmental filtering - few species dominate",
  "Low R, High E" = "Stable mature community with even species distribution",
  "High R, High E" = "High diversity with no dominant species",
  "High P signal" = "Phylogenetic clustering suggests habitat filtering",
  "High S signal" = "Spatial structure indicates dispersal limitation"
)

# Show detected patterns
print(patterns$detected_patterns)
```

### Assembly Mechanism Detection

Identify the ecological processes shaping your communities:

```{r assembly-mechanisms}
# Detect assembly mechanisms from diversity patterns
mechanisms <- detect_assembly_mechanisms(
  universal_info,
  environmental_data = sample_data(GlobalPatterns),
  test_mechanisms = c("filtering", "competition", "neutral", "dispersal")
)

# Show confidence scores for each mechanism
print(mechanisms$mechanism_scores)

# Get the dominant mechanism for each sample type
dominant_mechanisms <- mechanisms$dominant_by_group
print(dominant_mechanisms)
```

## AI-Powered Interpretation

### Basic AI Interpretation

Get ecological insights from diversity patterns:

```{r ai-basic, eval=FALSE}
# Ensure API key is set (see ?configure_llm)
check_api_setup()

# Generate interpretation
interpretation <- interpret_diversity(
  universal_info,
  context = list(
    study_type = "microbiome survey",
    environment = "multiple habitats",
    organism = "bacteria",
    question = "What drives diversity differences between habitats?"
  )
)

print(interpretation)
```

### Advanced Context-Aware Interpretation

Provide detailed context for more specific insights:

```{r ai-advanced, eval=FALSE}
# Detailed interpretation with hypothesis
detailed_interpretation <- interpret_diversity_patterns(
  patterns = patterns,
  universal_info = universal_info,
  context = list(
    environment = "human gut",
    treatment = "antibiotic exposure",
    timepoint = "post-treatment",
    hypothesis = "Antibiotics reduce diversity through selective pressure",
    previous_findings = "Pre-treatment showed high diversity"
  ),
  include_citations = TRUE
)

# Get specific sections
cat("Ecological Mechanisms:\n", detailed_interpretation$mechanisms, "\n\n")
cat("Testable Hypotheses:\n", detailed_interpretation$hypotheses, "\n\n")
cat("Recommended Analyses:\n", detailed_interpretation$recommendations, "\n")
```

## Hypothesis Generation

### From Patterns to Predictions

Generate testable hypotheses from diversity patterns:

```{r hypothesis-generation}
# Generate hypotheses based on patterns
hypotheses <- generate_ecological_hypotheses(
  patterns = patterns,
  universal_info = universal_info,
  study_design = list(
    type = "observational",
    comparisons = "between habitats",
    temporal = FALSE
  )
)

# Show generated hypotheses
for (i in seq_along(hypotheses$hypotheses)) {
  cat(paste0("Hypothesis ", i, ": ", hypotheses$hypotheses[[i]]$statement, "\n"))
  cat(paste0("  Confidence: ", hypotheses$hypotheses[[i]]$confidence, "\n"))
  cat(paste0("  Test: ", hypotheses$hypotheses[[i]]$suggested_test, "\n\n"))
}
```

### Mechanism-Based Predictions

Make predictions based on detected mechanisms:

```{r mechanism-predictions}
# Predict outcomes under different scenarios
predictions <- predict_diversity_outcomes(
  current_state = universal_info,
  scenarios = list(
    "increased_filtering" = list(
      change = "increase environmental stress",
      expected_R = "decrease",
      expected_E = "decrease"
    ),
    "reduced_dispersal" = list(
      change = "increase isolation",
      expected_S = "increase",
      expected_beta = "increase"
    )
  )
)

# Visualize predictions
plot_diversity_predictions(predictions)
```

## Biological Interpretation Examples

### Case 1: Antibiotic Treatment

```{r case-antibiotic}
# Simulate antibiotic effect (for demonstration)
# In practice, use your real data
antibiotic_samples <- sample_names(GlobalPatterns)[1:10]
control_samples <- sample_names(GlobalPatterns)[11:20]

# Compare groups
group_comparison <- compare_diversity_groups(
  div_results,
  group1 = antibiotic_samples,
  group2 = control_samples,
  group_names = c("Antibiotic", "Control")
)

# Interpret the comparison
interpretation <- interpret_group_comparison(
  group_comparison,
  biological_context = "antibiotic treatment",
  expected_outcome = "reduced diversity"
)

print(interpretation$summary)
```

### Case 2: Environmental Gradient

```{r case-gradient}
# Analyze diversity along an environmental gradient
# Using sample types as proxy for gradient
gradient_analysis <- analyze_diversity_gradient(
  universal_info,
  gradient = as.numeric(factor(sample_data(GlobalPatterns)$SampleType)),
  gradient_name = "Habitat complexity"
)

# Interpret gradient patterns
gradient_interpretation <- interpret_gradient_patterns(
  gradient_analysis,
  gradient_type = "environmental",
  expected_pattern = "increasing diversity with complexity"
)

# Plot with interpretation
plot(gradient_interpretation)
```

## Best Practices for Interpretation

### 1. Always Provide Context

```{r context-importance}
# Good: Specific context
good_context <- list(
  environment = "infant gut microbiome",
  age_range = "0-12 months",
  diet = "breast-fed vs formula-fed",
  hypothesis = "Breast-feeding promotes higher diversity"
)

# Poor: Vague context
poor_context <- list(
  environment = "gut",
  hypothesis = "diversity differs"
)
```

### 2. Validate AI Interpretations

```{r validate-ai, eval=FALSE}
# Get multiple interpretations
interp1 <- interpret_diversity(universal_info, provider = "anthropic")
interp2 <- interpret_diversity(universal_info, provider = "openai")

# Compare interpretations
compare_interpretations(interp1, interp2)
```

### 3. Combine Statistical and Biological Evidence

```{r combine-evidence}
# Statistical evidence
stats_evidence <- list(
  consensus_p_value = consensus_info$group_comparison$p_value,
  effect_size = consensus_info$group_comparison$effect_size,
  confidence_interval = consensus_info$confidence_interval
)

# Biological evidence
bio_evidence <- list(
  known_mechanisms = c("pH change", "nutrient availability"),
  previous_studies = c("Smith et al. 2020", "Jones et al. 2021"),
  ecological_theory = "competitive exclusion principle"
)

# Synthesize evidence
synthesis <- synthesize_evidence(
  statistical = stats_evidence,
  biological = bio_evidence,
  patterns = patterns
)

print(synthesis$conclusion)
```

## Advanced Consensus Techniques

### Hierarchical Consensus

Group similar metrics before consensus:

```{r hierarchical-consensus}
# Hierarchical consensus groups similar metrics
consensus_hierarchical <- consensus_diversity(
  div_results,
  method = "hierarchical",
  metric_groups = list(
    richness = c("observed", "chao1"),
    diversity = c("shannon", "simpson"),
    evenness = c("pielou_evenness")
  )
)

# Shows consensus within and between groups
print(consensus_hierarchical$group_consensus)
```

### Bayesian Consensus

Incorporate prior knowledge:

```{r bayesian-consensus}
# Bayesian consensus with priors
prior_weights <- c(
  shannon = 0.3,    # Historical preference
  simpson = 0.3,    # Historical preference
  observed = 0.2,   # Less reliable
  chao1 = 0.1,      # Often overestimates
  pielou_evenness = 0.1
)

consensus_bayesian <- consensus_diversity(
  div_results,
  method = "bayesian",
  prior_weights = prior_weights,
  prior_strength = 0.5  # How much to trust priors
)

print(consensus_bayesian$posterior_weights)
```

## Reporting Results

### Creating Interpretable Summaries

```{r create-summary}
# Create publication-ready summary
diversity_summary <- create_diversity_summary(
  consensus_results = consensus_info,
  universal_info = universal_info,
  interpretation = "AI or manual interpretation text",
  include_plots = TRUE
)

# Generate narrative
narrative <- generate_results_narrative(
  diversity_summary,
  style = "scientific",
  include_methods = TRUE
)

cat(narrative$text)
```

### Visualization for Communication

```{r communication-viz}
# Create figure for publication
pub_figure <- plot_diversity_synthesis(
  consensus_results = consensus_info,
  universal_info = universal_info,
  patterns = patterns,
  style = "publication"
)

# Add interpretation overlay
pub_figure + 
  annotate("text", x = 0.1, y = 0.9, 
           label = "Environmental filtering detected",
           hjust = 0, vjust = 1, size = 4, color = "darkred")
```

## Troubleshooting Interpretations

### When Consensus Fails

```{r consensus-troubleshoot}
# Check why consensus might fail
consensus_diagnostics <- diagnose_consensus_issues(div_results)

if (consensus_diagnostics$has_issues) {
  cat("Issues detected:\n")
  print(consensus_diagnostics$issues)
  
  # Get recommendations
  cat("\nRecommendations:\n")
  print(consensus_diagnostics$recommendations)
}
```

### Handling Outliers

```{r handle-outliers}
# Robust consensus excluding outliers
consensus_robust <- consensus_diversity(
  div_results,
  method = "weighted",
  robust = TRUE,
  outlier_threshold = 3  # MAD units
)

# Compare with non-robust
outliers_identified <- consensus_robust$outliers
cat("Outlier samples:", paste(outliers_identified, collapse = ", "))
```

## Conclusion

The ecological interpretation framework in diversityGPT transforms mathematical patterns into biological insights. By combining:

1. **Consensus algorithms** that resolve metric conflicts
2. **Universal information theory** that reveals underlying patterns
3. **AI-powered interpretation** that connects to ecological theory
4. **Hypothesis generation** that guides future research

You can move from confusion to clarity in diversity analysis. The key is providing rich context and validating interpretations against known biology.

For more details on the mathematical framework, see `vignette("universal-transformation")`. For interactive exploration, see `vignette("shiny-apps")`.